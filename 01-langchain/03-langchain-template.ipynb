{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Componentes Fundamentais:\n",
    "\n",
    "- **Models (Modelos):** LangChain serve como uma interface padrão que permite interações com uma ampla gama de Grandes Modelos de Linguagem (LLMs).\n",
    "\n",
    "- **Chains (Cadeias):** Como seu nome implica, _cadeias_ são o núcleo dos fluxos de trabalho do LangChain. Combinam LLMs com outros componentes, criando aplicativos por meio da execução de uma sequência de funções.\n",
    "\n",
    "- **Prompts (Instruções):** Os prompts são as instruções apresentadas a um LLM. Geralmente, a \"arte\" de redigir prompts que efetivamente entregam o contexto necessário para que o LLM interprete a entrada e a saída da estrutura da maneira mais útil para você é chamada de engenharia de prompt.\n",
    "\n",
    "- **Indexes (Índices):** Para realizar determinadas tarefas, as LLMs precisarão acessar fontes de dados externas específicas não incluídas em seu conjunto de dados de treinamento, como documentos internos, e-mails ou conjuntos de dados. LangChain refere-se coletivamente a essa documentação externa como “índices\".\"\n",
    "\n",
    "- **Memory (Memória):** Por padrão, os LLMs não têm memória de longo prazo de conversas anteriores (a menos que o histórico do chat seja usado como entrada para uma consulta). O LangChain soluciona esse problema com utilitários simples para adicionar memória a um sistema, com opções que vão desde a retenção total de todas as conversas até a retenção de um resumo da conversa até a retenção das _n_ trocas mais recentes.\n",
    "\n",
    "- **Agents/Tools (Agentes/Ferramentas):** Os agentes do LangChain podem usar um determinado modelo LLM como um \"mecanismo de raciocínio\" para determinar quais ações tomar. Ao criar uma cadeia para um agente, as entradas contêm:\n",
    "\n",
    "\t- uma lista de ferramentas disponíveis para serem aproveitadas.\n",
    "\t- entrada do usuário (como prompts e consultas).\n",
    "\t- quaisquer etapas relevantes executadas anteriormente.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../helpers/00-llm.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Importa conectando com o cliente OpenAI\n",
    "from helpers.llm import initialize_llm, logger, pretty_print\n",
    "\n",
    "# Parte 1 - Importando os componentes do LangChain\n",
    "llm, _, _ = initialize_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=========== Exemplo 1 =========\")\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"Gere para mim um poema sobre: {assunto}. Escreva em {lingua}\")\n",
    "retorno = prompt_template.invoke({\"assunto\": \"navegação\", \"lingua\":\"italiano\"})\n",
    "\n",
    "pretty_print(retorno)\n",
    "print(\"-------------------------------------------------------------------\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=========== Exemplo 2 =========\")\n",
    "\n",
    "template = '''\n",
    "Você é um analista financeiro.\n",
    "Escreva um relatório financeiro detalhado para a empresa \"{empresa}\" para o período {periodo}.\n",
    "\n",
    "O relatório deve ser escrito em {idioma} e incluir as seguintes análises:\n",
    "{analises}\n",
    "\n",
    "Certifique-se de fornecer insights e conclusões para cada seção.\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "empresa = 'ACME Corp'\n",
    "periodo = 'Q1 2024'\n",
    "idioma = 'Português'\n",
    "analises = [\n",
    "    \"Análise do Balanço Patrimonial\",\n",
    "    \"Análise do Fluxo de Caixa\",\n",
    "    \"Análise de Tendências\",\n",
    "    \"Análise de Receita e Lucro\",\n",
    "    \"Análise de Posição de Mercado\"\n",
    "]\n",
    "analises_text = \"\\n\".join([f\"- {analise}\" for analise in analises])\n",
    "\n",
    "print(analises_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(\n",
    "    empresa=empresa,\n",
    "    periodo=periodo,\n",
    "    idioma=idioma,\n",
    "    analises=analises_text\n",
    ")\n",
    "print(\"Prompt Gerado:\\n\", prompt)\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "pretty_print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=========== Exemplo 3 =========\")\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "\t\t\t\t\t\t\t\t\t  (\"system\", \"Você é um assistente de IA com habilidade de escritor de poesia.\"),\n",
    "\t\t\t\t\t\t\t\t\t  (\"user\", \"Gere para mim um poema sobre: {assunto}. Escreva em {lingua}\")\n",
    "])\n",
    "\n",
    "retorno = prompt_template.invoke({\"assunto\": \"navegação\", \"lingua\":\"italiano\"})\n",
    "pretty_print(retorno)\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "\n",
    "resposta = llm.invoke(retorno)\n",
    "\n",
    "pretty_print(resposta.content)\n",
    "print(\"-------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Exemplo Chain 1 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://trainning-grassato-01.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "No pomar da manhã, o sol desperta,  \n",
      "Entre folhas e galhos, a vida é certa.  \n",
      "Frutas pendem, coloridas, no ar,  \n",
      "Promessa doce de se saborear.\n",
      "\n",
      "A manga dourada, perfume no vento,  \n",
      "O cacho de uva, segredo e alento.  \n",
      "A maçã reluzente, tentação no olhar,  \n",
      "Banana macia, pronta pra descascar.\n",
      "\n",
      "O abacaxi, coroa de rei,  \n",
      "Ácido e doce, mistura que amei.  \n",
      "A melancia, frescor no verão,  \n",
      "Gotas vermelhas, festa na mão.\n",
      "\n",
      "Laranja e limão, cítricos irmãos,  \n",
      "Explodem sabores, despertam paixões.  \n",
      "Mamão e goiaba, doçura sem fim,  \n",
      "No pomar da vida, tudo é jardim.\n",
      "\n",
      "Frutas são cores, são risos, são festa,  \n",
      "São bênçãos da terra, banquete que resta.  \n",
      "No prato, no suco, no cheiro, no chão,  \n",
      "Frutas são versos do nosso verão.\n",
      "-------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "### Exemplo 1:\n",
    "# PART 1: Criando ChatPromptTemplate\n",
    "print(\"-----Exemplo Chain 1 -----\")\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"user\", \"Escreva um poema em {lingua} sobre o tema: {assunto}\")\n",
    "]\n",
    ")\n",
    "\n",
    "# PART 2: Criando a chain\n",
    "chain1 = prompt_template | llm\n",
    "\n",
    "# PART 3: Invoke da chain passando as variáveis.\n",
    "resposta = chain1.invoke({\"lingua\": \"pt-br\", \"assunto\":\"frutas\"})\n",
    "\n",
    "pretty_print(resposta.content)\n",
    "print(\"-------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exemplo 2:\n",
    "# PART 1: Criando ChatPromptTemplate já com mensagem de sistema:\n",
    "print(\"-----Exemplo Chain 2 -----\")\n",
    "\n",
    "mensagens = [\n",
    "    (\"system\", \"Você é um poeta brasileiro famoso e escreve poemas de no máximo {n_versos} versos.\"),\n",
    "    (\"human\", \"Escreva para mim um poema sobre {assunto}.\"),\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate(mensagens)\n",
    "\n",
    "# PART 2: Criando a chain\n",
    "chain2 = prompt_template | llm\n",
    "\n",
    "# PART 3: Invoke da chain passando as variáveis.\n",
    "resposta = chain2.invoke({\"n_versos\": \"10\", \"assunto\":\"navios\"})\n",
    "\n",
    "pretty_print(resposta.content)\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "resposta = llm.invoke(\"Qual a capital da França?\")\n",
    "pretty_print(resposta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchain)",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
