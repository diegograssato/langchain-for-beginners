{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defini√ß√£o\n",
    "\n",
    "Voc√™ consegue visualizar agora que todos os componentes LangChain apresentados, podem ser encadeados, uma vez que eles implementam a interface `Runnable`, ou seja, podemos montar nossas cadeias (chains) e, vale lembrar que a sa√≠da de um componente ser√° a entrada do pr√≥ximo componente.\n",
    "\n",
    "Chain portanto √© a cadeia formado por elementos de LangChain que implementam uma determinada a√ß√£o, principalmente envolvendo a atua√ß√£o de LLMs. Ou seja, a chain nada mais √© do que amarrar uma s√©rie de tarefas realizadas por cada componente em um √∫nico fluxo linear.\n",
    "\n",
    "Para esta aula preparei algo mais pr√°tico, ou seja, vamos praticar diferentes formas de encadeamento de componentes, por isso √© fundamental voc√™ ter visto as aulas anteriores e entender tamb√©m os `runnables` j√° que vamos utiliz√°-los em nossos exerc√≠cios.\n",
    "\n",
    "## Exemplo - B√°sico\n",
    "\n",
    "Vamos criar uma chain que √© a mais simples envolvendo um prompt, um modelo e um analisador de sa√≠da. J√° vimos em aulas anteriores, mas vale relembrar e √© um exemplo bom para come√ßarmos at√© aprofundar nas cadeias mais complexas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../helpers/00-llm.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.llm import initialize_llm, logger, pretty_print\n",
    "from langchain.prompts import ChatPromptTemplate  \n",
    "from langchain.schema.output_parser import StrOutputParser  \n",
    "from langchain_core.runnables import RunnableLambda  \n",
    "\n",
    "llm, _, embeddings = initialize_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definindo o prompt de comunica√ß√£o - adotamos aqui um estilo chat prompt  \n",
    "# template, uma vez que estamos usando o modelo do tipo chat.  \n",
    "  \n",
    "prompt_sistema = \"\"\"Voc√™ √© um assistente especialista em criar conte√∫do para o twitter e tem como objetivo   \n",
    "criar os melhores tweets virais sobre o tema que o usu√°rio te passar. Seja criativo e atenda ao padr√£o de 280 caracteres do   \n",
    "twitter.  \n",
    "\"\"\"  \n",
    "  \n",
    "prompt_template = ChatPromptTemplate(  \n",
    "    [  \n",
    "        (\"system\", prompt_sistema),  \n",
    "        (\"human\", \"Crie um total de {numero_de_publicacoes} tweets sobre o tema {input_tema}.\"),  \n",
    "    ]  \n",
    ")  \n",
    "  \n",
    "# Crie a cadeia combinada usando LangChain Expression Language (LCEL)  \n",
    "chain = prompt_template | llm | StrOutputParser()  \n",
    "  \n",
    "  \n",
    "# Executamos nossa chain  \n",
    "result = chain.invoke({\"numero_de_publicacoes\": 3, \"input_tema\": \"tecnologia\"})  \n",
    "  \n",
    "# Imprimimos a sa√≠da.  \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo - Chains sequenciais com fun√ß√µes personalizadas\n",
    "\n",
    "Vamos criar uma chain agora envolvendo a cria√ß√£o de fun√ß√µes personalizadas, ou seja, acoplaremos aqui a atua√ß√£o dos `RunnableLambda` para que possamos converter uma fun√ß√£o personalizada em componente LangChain e ser possivel adicionar nossa fun√ß√£o em meio √† cadeia.\n",
    "\n",
    "Digamos que n√≥s queremos confirmar se o total de caracteres de cada tweet est√° dentro dos 280 caracteres permitido. Vamos aproveitar o nosso exemplo anterior sobre a cria√ß√£o de tweets para gerar um relat√≥rio de valida√ß√£o.\n",
    "\n",
    "1. Vamos primeiro ajustar nosso prompt para que o LLM sempre gere o total de tweets separados por uma quebra de linha (\\n).\n",
    "2. Em seguida, vamos construir uma fun√ß√£o que funcionar√° como um analisador de saida personalizado ou seja, pegar√° a sa√≠da `string` do modelo e ir√° gerar uma lista em que cada elemento dessa lista ser√° um tweet criado pelo LLM. Aqui usaremos o `RunnableLambda` para nos ajudar.\n",
    "3. Depois teremos uma outra fun√ß√£o personalizada que analisa essa lista e conta o total de caracteres de cada tweet. O retorno dela ser√° um dicion√°rio com os resultado. Aqui usaremos o `RunnableLambda` para nos ajudar tamb√©m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma fun√ß√£o personalizada para tratar a saida textual do LLM  \n",
    "  \n",
    "def separador_de_tweet(entrada: str) -> list:  \n",
    "    \"\"\"  \n",
    "    Fun√ß√£o que recebe uma string e retorna uma lista com os elementos separados por quebras de linha.  \n",
    "    Args:        entrada (str): A string de entrada, onde os valores est√£o separados por quebras de linha.  \n",
    "    Returns:        list: Uma lista contendo cada elemento da string como um item separado.    \"\"\"    # Divide a string em uma lista utilizando o caractere de quebra de linha '\\n'  \n",
    "    elementos = entrada.split('\\n')  \n",
    "  \n",
    "    # Remove espa√ßos extras e ignora linhas vazias  \n",
    "    elementos_limpos = [elemento.strip() for elemento in elementos if elemento.strip()]  \n",
    "  \n",
    "    return elementos_limpos  \n",
    "  \n",
    "# Criando uma fun√ß√£o personalizada pegar a lista criada na fun√ß√£o anterior e gerar um dicion√°rio com o rel√°torio de  \n",
    "# analise de caracteres.  \n",
    "  \n",
    "def relatorio_de_analise_de_caracteres(entrada: list) -> dict:  \n",
    "    \"\"\"  \n",
    "    Fun√ß√£o que gera um relat√≥rio com os tweets e a contagem de caracteres de cada tweet.  \n",
    "    Args:        entrada (list): Lista de strings representando os tweets.  \n",
    "    Returns:        dict: Um dicion√°rio com duas chaves:              - 'tweets': contendo a lista original.              - 'num_caract': contendo uma lista com o n√∫mero de caracteres de cada tweet.    \"\"\"    # Gera a contagem de caracteres para cada item na lista  \n",
    "    contagem_caracteres = [len(tweet) for tweet in entrada]  \n",
    "  \n",
    "    # Monta o dicion√°rio de sa√≠da  \n",
    "    relatorio = {  \n",
    "        'tweets': entrada,  \n",
    "        'num_caract': contagem_caracteres  \n",
    "    }  \n",
    "  \n",
    "    return relatorio  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "  \n",
    "# Definindo o prompt de comunica√ß√£o - adotamos aqui um estilo chat prompt  \n",
    "# template, uma vez que estamos usando o modelo do tipo chat.  \n",
    "  \n",
    "prompt_sistema = \"\"\"Voc√™ √© um assistente especialista em criar conte√∫do para o twitter e tem como objetivo  \n",
    "criar os melhores tweets virais sobre o tema que o usu√°rio te passar. Seja criativo e atenda ao padr√£o de 280 caracteres do   \n",
    "twitter.  \n",
    "Orienta√ß√£o:  \n",
    "- Crie apenas o numero de tweets informado.  \n",
    "- Separe cada um deles por uma quebra de linha,  \n",
    "\"\"\"  \n",
    "  \n",
    "prompt_template = ChatPromptTemplate(  \n",
    "    [  \n",
    "        (\"system\", prompt_sistema),  \n",
    "        (\"human\", \"Crie um total de {numero_de_publicacoes} tweets sobre o tema {input_tema}.\"),  \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie a cadeia combinada usando LangChain Expression Language (LCEL).  \n",
    "# para adicionar os outros componentes personalizados √† cadeia, precisamos converter as fun√ß√µes em um componente langchain, para isso  \n",
    "# precisamos usar o RunnableLambda.  \n",
    "  \n",
    "chain = prompt_template | llm | StrOutputParser() | RunnableLambda(separador_de_tweet) | RunnableLambda(relatorio_de_analise_de_caracteres)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executamos nossa chain  \n",
    "result = chain.invoke({\"numero_de_publicacoes\": 3, \"input_tema\": \"tecnologia\"})  \n",
    "  \n",
    "# Imprimimos o nosso dicion√°rio de relat√≥rio:  \n",
    "print(result)  \n",
    "print(\"-\"*50)  \n",
    "  \n",
    "# imprimindo de forma mais estruturada:  \n",
    "for i, (tweet, num_caract) in enumerate(zip(result['tweets'], result['num_caract']), start=1):  \n",
    "        print(f\"Tweet {i}: {tweet}\")  \n",
    "        print(f\"Total de caracteres: {num_caract}\")  \n",
    "        if num_caract <= 280:  \n",
    "            print(\"Valida√ß√£o: OK\")  \n",
    "        else:  \n",
    "            print(\"Valida√ß√£o: Tweet supera o limite de 280 caracteres\")  \n",
    "        print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo - Chains de execu√ß√£o paralela\n",
    "\n",
    "Agora vamos a um problema mais complexo, imagine que queremos criar um assistente que recebe uma review de um filme e ele tem que analisar pr√≥s e contras comentados no review entregue na entrada.\n",
    "\n",
    "Para que possamos entender a execu√ß√£o paralela de chain, vamos criar uma arquitetura onde a an√°lise pr√≥ e contra s√£o realizadas de forma paralela, e no final vamos unir os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o prompt de comunica√ß√£o - adotamos aqui um estilo chat prompt  \n",
    "# template, uma vez que estamos usando o modelo do tipo chat.  \n",
    "  \n",
    "prompt_template = ChatPromptTemplate.from_messages(  \n",
    "    [  \n",
    "        (\"system\", \"Voc√™ √© um escritor especialista em an√°lises de review de filmes de cinema.\"),  \n",
    "        (\"human\", \"Liste de forma estruturada os principais detalhes e pontos de vistas apresentados na seguinte  review entregue pelo usu√°rio n√£o invente nada apenas capture as principais informa√ß√µes apresentadas. Review: {movie_review}.\"),  \n",
    "    ]  \n",
    ")  \n",
    "\n",
    "  \n",
    "# Vamos definir um bra√ßo da nossa chain que ser√° uma cadeia intermedi√°ria de analise dos pontos positivos sobre a review.  \n",
    "  \n",
    "analise_ponto_positivo_template = ChatPromptTemplate(  \n",
    "    [  \n",
    "        (\"system\", \"Voc√™ √© um analista cr√≠tico de filmes de cinema\"),  \n",
    "        (  \n",
    "            \"human\", \"Dados este review estruturado: {review_estruturado}, liste os pontos positivos do filme.\",  \n",
    "        ),  \n",
    "    ]  \n",
    ")  \n",
    "\n",
    "# criando a chain do bra√ßo 1  \n",
    "chain_intermediaria_positiva = analise_ponto_positivo_template | llm | StrOutputParser()  \n",
    "  \n",
    "# -------------------------------------------------------------------------------- \n",
    "  \n",
    "# Vamos definir outro bra√ßo da nossa chain que ser√° uma cadeia intermedi√°ria de analise dos pontos negativos sobre a review.  \n",
    "  \n",
    "analise_ponto_negativo_template = ChatPromptTemplate(  \n",
    "    [  \n",
    "        (\"system\", \"Voc√™ √© um analista cr√≠tico de filmes de cinema\"),  \n",
    "        (  \n",
    "            \"human\", \"Dados este review estruturado: {review_estruturado}, liste os pontos negativos do filme.\",  \n",
    "        ),  \n",
    "    ]  \n",
    ")  \n",
    "  \n",
    "# criando a chain do bra√ßo 2  \n",
    "chain_intermediaria_negativa = analise_ponto_negativo_template | llm | StrOutputParser()  \n",
    "  \n",
    "# -------------------------------------------------------------------------------- \n",
    "  \n",
    "# Fun√ß√£o respons√°vel por combinar os resultados dos bra√ßos que v√£o ser executados em paralelo.  \n",
    "def combinando_analises(entrada: dict):  \n",
    "    return f\"An√°lise positiva:\\n{entrada['posivita']}\\n\\nAn√°lise negativa:\\n{entrada['negativa']}\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie a cadeia combinada usando LangChain Expression Language (LCEL)  \n",
    "# Em RunnableLambda(lambda x: {\"review_estruturado\": x}) estamos convertendo a saida string para um dicion√°rio  \n",
    "# com a chave 'review_estruturado' que os templates das chains intermedi√°rias exige como entrada.  \n",
    "  \n",
    "chain = (prompt_template  \n",
    "         | llm  \n",
    "         | StrOutputParser()  \n",
    "         | RunnableLambda(lambda x: {\"review_estruturado\": x})  \n",
    "         | {\"posivita\": chain_intermediaria_positiva, \"negativa\": chain_intermediaria_negativa}  \n",
    "         | RunnableLambda(combinando_analises)  \n",
    "         )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executando nossa chain principal.  \n",
    "movie_review =\"\"\"Cr√≠tica de \"O Gladiador 2\"  \n",
    "\"O Gladiador 2\", dirigido por Ridley Scott, chega aos cinemas com a expectativa de reviver a grandiosidade √©pica de   \n",
    "seu antecessor. No entanto, apesar do hist√≥rico impressionante de Scott, que inclui cl√°ssicos como \"Blade Runner\" e   \n",
    "\"Alien\", o filme parece trope√ßar em sua pr√≥pria ambi√ß√£o.  \n",
    "  \n",
    "Desde o in√≠cio, o filme tenta inovar ao incorporar cenas animadas e elementos de intelig√™ncia artificial,   \n",
    "possivelmente como uma homenagem ao primeiro \"Gladiador\". No entanto, essa escolha est√©tica, embora ousada,   \n",
    "n√£o se integra de maneira fluida √† narrativa, criando uma desconex√£o que pode confundir o espectador.  \n",
    "  \n",
    "A tentativa de trazer novidade √†s lutas no Coliseu, com a introdu√ß√£o de navios vikings e tubar√µes, √© um exemplo   \n",
    "de como o filme busca surpreender. No entanto, essas cenas acabam por sacrificar a autenticidade hist√≥rica em prol   \n",
    "do espet√°culo, o que pode afastar aqueles que esperavam uma representa√ß√£o mais fiel das arenas romanas. A inclus√£o   \n",
    "de macacos em combate, por sua vez, remete a outras franquias cinematogr√°ficas, diluindo ainda mais a originalidade   \n",
    "do enredo.  \n",
    "  \n",
    "Apesar dessas escolhas question√°veis, √© importante reconhecer o esfor√ßo de Scott em tentar oferecer algo novo e   \n",
    "visualmente impactante. No entanto, a falta de uma pesquisa hist√≥rica mais aprofundada se faz sentir, e o filme   \n",
    "poderia ter se beneficiado de uma abordagem mais cuidadosa nesse aspecto.  \n",
    "  \n",
    "Em suma, \"O Gladiador 2\" √© uma obra que, embora repleta de potencial e com momentos de brilho visual, acaba por se   \n",
    "perder em sua tentativa de inovar. Para os f√£s do g√™nero e do diretor, pode ser uma experi√™ncia mista, que levanta   \n",
    "quest√µes sobre at√© que ponto a inova√ß√£o deve ir sem comprometer a ess√™ncia e a coer√™ncia da narrativa.  \n",
    "\"\"\"  \n",
    "  \n",
    "result = chain.invoke({\"movie_review\": movie_review})  \n",
    "  \n",
    "# --------------------------------------------------------------------------------\n",
    "# Imprimindo a saida.  \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo - Chain de roteamento (Branch)\n",
    "\n",
    "Agora vamos a um problema onde teremos uma fun√ß√£o de roteamento. Essa fun√ß√£o ter√° a fun√ß√£o de decidir, usando a classifica√ß√£o por meio de um LLM, para qual branch (bra√ßo/ramo) da nossa chain o programa deve seguir e finalizar.\n",
    "\n",
    "Imagine um sistema de atendimento com duas rotas: (1) quando o usu√°rio solicita que seja atendido por um  humano, encaminhamos a pergunta para um atendente humano e finalizamos a cadeia ou (2) quando o usu√°rio apenas deseja tirar d√∫vidas sobre um produto, nosso sistema escolhe enviar a pergunta para uma chain que implementa um bot capaz de responder √†s d√∫vidas desse usu√°rio e finaliza a itera√ß√£o.\n",
    "\n",
    "A pe√ßa principal desse nosso sistema est√° na cria√ß√£o de uma fun√ß√£o que far√° esse roteamento entre cadeias de LangChain. No nosso caso, voc√™ pode observar isso na fun√ß√£o 'executa_roteamento' implementada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser  \n",
    "from pydantic import BaseModel, Field \n",
    "\n",
    "## Definindo a estrutura da chain que vai avaliar a entrada e retornar uma classifica√ß√£o para nossa fun√ß√£o 'executa_roteamento'  \n",
    "# Definindo a minha estrutura de sa√≠da usando Pydantic  \n",
    "class Rota(BaseModel):  \n",
    "    opcao: bool = Field(description=\"Defina True se necessitar atendimento humano e false caso contr√°rio.\")  \n",
    "    pergunta_user: str = Field(description=\"Colocar neste parametro a pergunta do usu√°rio sem alter√°-la.\")  \n",
    "  \n",
    "  \n",
    "parser = PydanticOutputParser(pydantic_object=Rota)  \n",
    "  \n",
    "sys_prompt_rota = \"\"\"Voc√™ √© um especialista em classifica√ß√£o. Voc√™ receber√° perguntas do usu√°rio e precisar√° classificar, \n",
    "de forma booleana, se o usu√°rio est√° solicitando conversar com um atendente humano ou n√£o.  \n",
    "\\n{format_instructions}\\n  \n",
    "Pergunta Usu√°rio: {pergunta_user}\"  \n",
    "\"\"\"  \n",
    "  \n",
    "rota_prompt_template = ChatPromptTemplate([(\"system\", sys_prompt_rota),],  \n",
    "                                          partial_variables={\"format_instructions\": parser.get_format_instructions()}  \n",
    "                                          )  \n",
    "  \n",
    "# criando o peda√ßo da chain que controla o roteamento entre as branches  \n",
    "chain_de_roteamento = rota_prompt_template | llm | parser  \n",
    "  \n",
    "# Se quiser testar a cadeia intermedi√°ria de roteamento:  \n",
    "# result = chain_de_roteamento.invoke({\"pergunta_user\": \"Quero falar com um humano\"})  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o prompt de chatbot que tira duvidas do usu√°rio:  \n",
    "  \n",
    "sys_chatbot_prompt = \"\"\" Voc√™ √© um assistente de uma clinica odontol√≥gica e tem como objetivo responder √† perguntas dos clientes. A seguir voc√™  \n",
    "encontra a FAQ do nosso site, use essas informa√ß√µes para realizar o atendimento e tirar d√∫vidas. Caso voc√™ desconhe√ßa alguma  \n",
    "informa√ß√£o, n√£o invente. Seja sempre amig√°vel e esteja disposto a ajudar!  \n",
    "  \n",
    "**FAQ - Cl√≠nica Odontol√≥gica**  \n",
    "1. **Quais servi√ßos a cl√≠nica oferece?**    \n",
    "   Oferecemos tratamentos como limpeza dental, clareamento, ortodontia, implantes, pr√≥teses, tratamento de canal e est√©tica dental.  \n",
    "2. **A cl√≠nica aceita conv√™nios?**    \n",
    "   Sim, trabalhamos com os principais conv√™nios odontol√≥gicos. Consulte nossa equipe para verificar se aceitamos o seu.  \n",
    "3. **Como agendar uma consulta?**    \n",
    "   Voc√™ pode agendar sua consulta pelo telefone, WhatsApp ou diretamente em nosso site.  \n",
    "4. **Quanto tempo dura uma consulta?**    \n",
    "   Depende do procedimento, mas consultas de rotina geralmente duram entre 30 e 60 minutos.  \n",
    "5. **Voc√™s atendem emerg√™ncias?**    \n",
    "   Sim, oferecemos atendimento emergencial para dores agudas, traumas ou casos de urg√™ncia.  \n",
    "6. **√â poss√≠vel parcelar tratamentos?**    \n",
    "   Sim, oferecemos op√ß√µes de parcelamento. Entre em contato para conhecer os detalhes.  \n",
    "7. **Crian√ßas podem ser atendidas na cl√≠nica?**    \n",
    "   Sim, contamos com profissionais especializados em odontopediatria para cuidar dos sorrisos dos pequenos.  \n",
    "8. **O clareamento dental √© seguro?**    \n",
    "   Sim, nossos tratamentos de clareamento s√£o realizados com t√©cnicas e produtos seguros, supervisionados por especialistas.  \n",
    "Se tiver mais d√∫vidas, entre em contato conosco! üòä  \n",
    "  \n",
    "D√∫vida do usu√°rio: {pergunta_user}  \n",
    "\"\"\"  \n",
    "  \n",
    "prompt_template_chatbot = ChatPromptTemplate.from_messages([(\"system\", sys_chatbot_prompt),])  \n",
    "  \n",
    "chain_chatbot = prompt_template_chatbot | llm | StrOutputParser()  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definindo a fun√ß√£o de escolha de roteamento (n√≥ de rota)  \n",
    "def executa_roteamento(entrada: Rota):  \n",
    "    if entrada.opcao:  \n",
    "        print(f\"Op√ß√£o classe Pydantic: {entrada.opcao} (Atendimento humano)\")  \n",
    "        return \"Atendimento redirecionado para um humano. Favor aguardar alguns minutos que j√° vamos te atender!\"  \n",
    "    else:  \n",
    "        print(f\"Op√ß√£o classe Pydantic: {entrada.opcao} (Atendimento Chatbot)\")  \n",
    "        return RunnableLambda(lambda x: {\"pergunta_user\": x.pergunta_user}) | chain_chatbot  \n",
    "\n",
    "\n",
    "# Crie a cadeia final usando LangChain Expression Language (LCEL)  \n",
    "chain = chain_de_roteamento | RunnableLambda(executa_roteamento) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executando nossa chain principal.  \n",
    "result = chain.invoke({\"pergunta_user\": \"Quais servi√ßos a cl√≠nica oferece?\"})  \n",
    "  \n",
    "# -------------------------------------------------------------------------------- \n",
    "# Imprimindo a saida.  \n",
    "print(\"---------------\")  \n",
    "print(result)  \n",
    "print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Por que usar RouterChains?\n",
    "A principal vantagem de usar RouterChains √© a capacidade de criar aplica√ß√µes mais robustas e flex√≠veis. Imagine que voc√™ est√° desenvolvendo um chatbot para uma loja online. Com RouterChains, voc√™ pode direcionar perguntas sobre produtos eletr√¥nicos para um especialista em eletr√¥nicos, enquanto perguntas sobre roupas s√£o direcionadas para um especialista em moda. Isso melhora a precis√£o e a relev√¢ncia das respostas, proporcionando uma melhor experi√™ncia ao usu√°rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Classifique a pergunta do usu√°rio em uma das seguintes categorias:\n",
    "        - Matem√°tica\n",
    "        - F√≠sica\n",
    "        - Qu√≠mica\n",
    "        - Outras Informa√ß√µes\n",
    "\n",
    "        Pergunta: {query}\n",
    "        Classifica√ß√£o:\n",
    "        \"\"\"\n",
    "    )\n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")\n",
    "# Definindo os prompts especializados\n",
    "chain_fisica = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Voc√™ √© um professor de f√≠sica muito inteligente. Assuntos detalhados:\n",
    "        - Mec√¢nica: Estuda o movimento e as causas que o produzem ou alteram. Inclui cinem√°tica (estudo do movimento sem considerar suas causas), din√¢mica (estudo das for√ßas que causam o movimento) e est√°tica (estudo do equil√≠brio de corpos). \n",
    "        - Termologia: Estuda o calor, a temperatura e suas rela√ß√µes. Abrange t√≥picos como calorimetria (estudo da troca de calor), termodin√¢mica (estudo das leis que regem as transforma√ß√µes de energia t√©rmica), e estados f√≠sicos da mat√©ria. \n",
    "        - Ondulat√≥ria: Estuda as ondas, fen√¥menos como a propaga√ß√£o de energia atrav√©s de um meio ou do espa√ßo. \n",
    "        - √ìptica: Estuda a luz e seus fen√¥menos, como reflex√£o, refra√ß√£o, difra√ß√£o e interfer√™ncia. \n",
    "        - Eletromagnetismo: Estuda os fen√¥menos relacionados √† eletricidade e ao magnetismo, incluindo eletrost√°tica (estudo das cargas el√©tricas em repouso), eletrodin√¢mica (estudo das cargas em movimento), e magnetismo. \n",
    "        - Pessoas influentes da area\n",
    "        - Outras Informa√ß√µes\n",
    "\n",
    "        Pergunta: {query} \n",
    "        Resposta:\n",
    "        \"\"\"\n",
    "    )\n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")\n",
    "chain_matematica = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Voc√™ √© um professor de matem√°tica muito inteligente. Assuntos detalhados:\n",
    "        - √Ålgebra: Estuda as opera√ß√µes e rela√ß√µes entre n√∫meros, incluindo equa√ß√µes, fun√ß√µes e polin√¥mios.\n",
    "        - Geometria: Estuda as propriedades e rela√ß√µes de pontos, linhas, superf√≠cies e s√≥lidos no espa√ßo.\n",
    "        - Trigonometria: Estuda as rela√ß√µes entre os √¢ngulos e os lados dos tri√¢ngulos.\n",
    "        - C√°lculo: Estuda as taxas de varia√ß√£o e as somas infinitas, incluindo derivadas e integrais.\n",
    "        - Estat√≠stica: Estuda a coleta, an√°lise e interpreta√ß√£o de dados num√©ricos.\n",
    "        - Pessoas influentes da area\n",
    "        - Outras Informa√ß√µes\n",
    "\n",
    "        Pergunta: {query} \n",
    "        Resposta:\n",
    "        \"\"\"\n",
    "    )\n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")\n",
    "chain_quimica = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Voc√™ √© um professor de qu√≠mica muito inteligente. Assuntos detalhados:\n",
    "        - Estrutura At√¥mica: Estudo da composi√ß√£o do √°tomo, incluindo part√≠culas subat√¥micas (pr√≥tons, n√™utrons, el√©trons), evolu√ß√£o dos modelos at√¥micos e distribui√ß√£o eletr√¥nica. \n",
    "        - Tabela Peri√≥dica: Organiza√ß√£o dos elementos qu√≠micos, suas propriedades peri√≥dicas (eletroafinidade, energia de ioniza√ß√£o, etc.) e rela√ß√£o com a estrutura at√¥mica. \n",
    "        - Liga√ß√µes Qu√≠micas: Tipos de liga√ß√µes (i√¥nica, covalente, met√°lica) e suas caracter√≠sticas, al√©m de geometria molecular e polaridade. \n",
    "        - Fun√ß√µes Inorg√¢nicas: Estudo de √°cidos, bases, sais e √≥xidos, suas propriedades e rea√ß√µes. \n",
    "        - Rea√ß√µes Qu√≠micas: Tipos de rea√ß√µes, balanceamento de equa√ß√µes, reagente limitante, rendimento da rea√ß√£o e c√°lculo estequiom√©trico. \n",
    "        - C√°lculos Qu√≠micos: Conceito de mol, n√∫mero de Avogadro, massa molar, volume molar e c√°lculos relacionados a rea√ß√µes qu√≠micas. \n",
    "        - Termoqu√≠mica: Estudo do calor envolvido nas rea√ß√µes qu√≠micas, entalpia, lei de Hess e aplica√ß√µes. \n",
    "        - Eletroqu√≠mica: Estudo da rela√ß√£o entre eletricidade e rea√ß√µes qu√≠micas, pilhas, eletr√≥lise e potenciais de eletrodo. \n",
    "        - Qu√≠mica Org√¢nica: Estudo dos compostos de carbono, fun√ß√µes org√¢nicas, isomeria e rea√ß√µes org√¢nicas. \n",
    "        - Misturas e Separa√ß√£o de Misturas: Tipos de misturas (homog√™neas e heterog√™neas), m√©todos de separa√ß√£o (filtra√ß√£o, destila√ß√£o, decanta√ß√£o, etc.). \n",
    "        - Equil√≠brio Qu√≠mico: Conceito de equil√≠brio qu√≠mico, constantes de equil√≠brio, deslocamento do equil√≠brio. \n",
    "        - Qu√≠mica Ambiental: Estudo da polui√ß√£o ambiental, tratamento de res√≠duos e impacto das atividades humanas no meio ambiente. \n",
    "        - Radioatividade: Desintegra√ß√£o radioativa, tipos de radia√ß√£o, meia-vida e aplica√ß√µes da radioatividade.  \n",
    "        - Pessoas influentes da area\n",
    "        - Outras Informa√ß√µes\n",
    "\n",
    "        Pergunta: {query} \n",
    "        Resposta:\n",
    "        \"\"\"\n",
    "    )\n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")\n",
    "\n",
    "chain_prompt = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Responda √† seguinte pergunta:\n",
    "\n",
    "        Pergunta: {query} \n",
    "        Resposta:\n",
    "        \"\"\"\n",
    "    )\n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um RunnableBranch √© um tipo especial de execut√°vel que permite definir um conjunto de condi√ß√µes e execut√°veis a serem executados com base na entrada. Ele n√£o oferece nada que voc√™ n√£o possa obter em uma fun√ß√£o personalizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "branch = RunnableBranch(\n",
    "    (lambda x: \"f√≠sica\" in x[\"topic\"].lower(), chain_fisica),\n",
    "    (lambda x: \"qu√≠mica\" in x[\"topic\"].lower(), chain_quimica),\n",
    "    (lambda x: \"matem√°tica\" in x[\"topic\"].lower(), chain_matematica),\n",
    "    chain_prompt,\n",
    ")\n",
    " \n",
    "\n",
    "full_chain = {\"topic\": chain, \"query\": lambda x: x[\"query\"]} | branch\n",
    "pretty_print(full_chain.invoke({\"query\": \"Quanto √© 2 +2?\"}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    " \n",
    "\n",
    "# ela inicial (classifica√ß√£o)\n",
    "chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Classifique a pergunta do usu√°rio em uma das seguintes categorias:\n",
    "        - Assuntos Financeiros\n",
    "        - Suporte T√©cnico\n",
    "        - Atualiza√ß√£o de Cadastro\n",
    "        - Outras Informa√ß√µes\n",
    "\n",
    "        Pergunta: {query}\n",
    "        Classifica√ß√£o:\n",
    "        \"\"\"\n",
    "    )\n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")\n",
    "\n",
    "# elos espec√≠ficos\n",
    "financial_chain = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Voc√™ √© um especialista financeiro.\n",
    "    Sempre responda √†s perguntas come√ßando com \"Bem-vindo ao Suporte Financeiro\".\n",
    "    Responda √† pergunta do usu√°rio:\n",
    "    Pergunta: {query}\n",
    "    Resposta:\n",
    "    \"\"\"\n",
    ") | llm\n",
    "tech_support_chain = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Voc√™ √© um especialista em suporte t√©cnico.\n",
    "    Sempre responda √†s perguntas come√ßando com \"Bem-vindo ao Suporte T√©cnico\".\n",
    "    Ajude o usu√°rio com seu problema t√©cnico.\n",
    "    Pergunta: {query}\n",
    "    Resposta:\n",
    "    \"\"\"\n",
    ") | llm\n",
    "update_registration_chain = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Voc√™ √© um representante de atendimento ao cliente.\n",
    "    Sempre responda √†s perguntas come√ßando com \"Bem-vindo ao Suporte de Cadastro\".\n",
    "    Guie o usu√°rio na atualiza√ß√£o de suas informa√ß√µes de cadastro.\n",
    "    Pergunta: {query}\n",
    "    Resposta:\n",
    "    \"\"\"\n",
    ") | llm\n",
    "other_info_chain = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Voc√™ √© um assistente de informa√ß√µes gerais.\n",
    "    Sempre responda √†s perguntas come√ßando com \"Bem-vindo ao Suporte Geral\".\n",
    "    Forne√ßa informa√ß√µes ao usu√°rio sobre sua pergunta.\n",
    "    Pergunta: {query}\n",
    "    Resposta:\n",
    "    \"\"\"\n",
    ") | llm\n",
    " \n",
    " \n",
    "# Usando a RouterChain\n",
    "#resposta = router_chain.run(\"Qual √© a segunda Lei de Newton?\")\n",
    "#print(resposta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o de roteamento\n",
    "def route(info):\n",
    "    topic = info[\"topic\"].lower()\n",
    "    if \"financeiro\" in topic:\n",
    "        return financial_chain\n",
    "    elif \"t√©cnico\" in topic:\n",
    "        return tech_support_chain\n",
    "    elif \"atualiza√ß√£o\" in topic or \"cadastro\" in topic:\n",
    "        return update_registration_chain\n",
    "    else:\n",
    "        return other_info_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplos 1 suporte t√©cnico\n",
    "classification = chain.invoke({\"query\": \"Como fa√ßo para redefinir minha senha?\"})\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chama a fun√ß√£o rote, passando o topico\n",
    "response_chain = route({\"topic\": classification})\n",
    "print(response_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#executa o objeto correto\n",
    "response = response_chain.invoke({\"query\": \"Como fa√ßo para redefinir minha senha?\"})\n",
    "pretty_print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "router_chain = {\"topic\": chain, \"query\": lambda x: x[\"query\"]} | RunnableLambda(\n",
    "    route\n",
    ")\n",
    "\n",
    "query = \"Qual √© a miss√£o da empresa?\"\n",
    "#query = \"Como posso pagar uma fatura atrasada?\"\n",
    "#query = \"Preciso alterar meu endere√ßo de e-mail.\"\n",
    "\n",
    "#query = \"Como fa√ßo para redefinir minha senha?\"\n",
    "\n",
    "resposta = router_chain.invoke({\"query\": query})\n",
    "pretty_print(resposta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "physics_template = \"\"\"Voc√™ √© um professor de f√≠sica muito inteligente.\n",
    "Voc√™ √© √≥timo em responder perguntas sobre f√≠sica de forma concisa e f√°cil de entender.\n",
    "Quando voc√™ n√£o sabe a resposta para uma pergunta, voc√™ admite que n√£o sabe. \n",
    "\n",
    "Aqui vai uma pergunta, seja curto na resposta:\n",
    "{query}\"\"\"\n",
    "\n",
    "math_template = \"\"\"Voc√™ √© um matem√°tico muito bom. \n",
    "Voc√™ √© √≥timo em responder perguntas de matem√°tica.\n",
    "Voc√™ √© t√£o bom porque consegue decompor problemas dif√≠ceis em suas partes componentes, responder √†s partes componentes e, em seguida, junt√°-las para responder √† quest√£o mais ampla.\n",
    "\n",
    "Aqui est√° uma pergunta, seja curto na resposta:\n",
    "{query}\"\"\"\n",
    "\n",
    "prompt_templates = [physics_template, math_template]\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
    " \n",
    "def prompt_router(input):\n",
    "    query_embedding = embeddings.embed_query(input[\"query\"])\n",
    "    \n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "    \n",
    "    most_similar = prompt_templates[similarity.argmax()]  \n",
    " \n",
    "    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\")\n",
    "    return PromptTemplate.from_template(most_similar)\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"query\": RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.invoke(\"What's a path integral?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchain)",
   "language": "python",
   "name": "grassato"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
