{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição\n",
    "\n",
    "Você consegue visualizar agora que todos os componentes LangChain apresentados, podem ser encadeados, uma vez que eles implementam a interface `Runnable`, ou seja, podemos montar nossas cadeias (chains) e, vale lembrar que a saída de um componente será a entrada do próximo componente.\n",
    "\n",
    "Chain portanto é a cadeia formado por elementos de LangChain que implementam uma determinada ação, principalmente envolvendo a atuação de LLMs. Ou seja, a chain nada mais é do que amarrar uma série de tarefas realizadas por cada componente em um único fluxo linear.\n",
    "\n",
    "Para esta aula preparei algo mais prático, ou seja, vamos praticar diferentes formas de encadeamento de componentes, por isso é fundamental você ter visto as aulas anteriores e entender também os `runnables` já que vamos utilizá-los em nossos exercícios.\n",
    "\n",
    "## Exemplo - Básico\n",
    "\n",
    "Vamos criar uma chain que é a mais simples envolvendo um prompt, um modelo e um analisador de saída. Já vimos em aulas anteriores, mas vale relembrar e é um exemplo bom para começarmos até aprofundar nas cadeias mais complexas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../helpers/00-llm.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.llm import initialize_llm, logger, pretty_print\n",
    "from langchain.prompts import ChatPromptTemplate  \n",
    "from langchain.schema.output_parser import StrOutputParser  \n",
    "from langchain_core.runnables import RunnableLambda  \n",
    "\n",
    "llm, _, embeddings = initialize_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definindo o prompt de comunicação - adotamos aqui um estilo chat prompt  \n",
    "# template, uma vez que estamos usando o modelo do tipo chat.  \n",
    "  \n",
    "prompt_sistema = \"\"\"Você é um assistente especialista em criar conteúdo para o twitter e tem como objetivo   \n",
    "criar os melhores tweets virais sobre o tema que o usuário te passar. Seja criativo e atenda ao padrão de 280 caracteres do   \n",
    "twitter.  \n",
    "\"\"\"  \n",
    "  \n",
    "prompt_template = ChatPromptTemplate(  \n",
    "    [  \n",
    "        (\"system\", prompt_sistema),  \n",
    "        (\"human\", \"Crie um total de {numero_de_publicacoes} tweets sobre o tema {input_tema}.\"),  \n",
    "    ]  \n",
    ")  \n",
    "  \n",
    "# Crie a cadeia combinada usando LangChain Expression Language (LCEL)  \n",
    "chain = prompt_template | llm | StrOutputParser()  \n",
    "  \n",
    "  \n",
    "# Executamos nossa chain  \n",
    "result = chain.invoke({\"numero_de_publicacoes\": 3, \"input_tema\": \"tecnologia\"})  \n",
    "  \n",
    "# Imprimimos a saída.  \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo - Chains sequenciais com funções personalizadas\n",
    "\n",
    "Vamos criar uma chain agora envolvendo a criação de funções personalizadas, ou seja, acoplaremos aqui a atuação dos `RunnableLambda` para que possamos converter uma função personalizada em componente LangChain e ser possivel adicionar nossa função em meio à cadeia.\n",
    "\n",
    "Digamos que nós queremos confirmar se o total de caracteres de cada tweet está dentro dos 280 caracteres permitido. Vamos aproveitar o nosso exemplo anterior sobre a criação de tweets para gerar um relatório de validação.\n",
    "\n",
    "1. Vamos primeiro ajustar nosso prompt para que o LLM sempre gere o total de tweets separados por uma quebra de linha (\\n).\n",
    "2. Em seguida, vamos construir uma função que funcionará como um analisador de saida personalizado ou seja, pegará a saída `string` do modelo e irá gerar uma lista em que cada elemento dessa lista será um tweet criado pelo LLM. Aqui usaremos o `RunnableLambda` para nos ajudar.\n",
    "3. Depois teremos uma outra função personalizada que analisa essa lista e conta o total de caracteres de cada tweet. O retorno dela será um dicionário com os resultado. Aqui usaremos o `RunnableLambda` para nos ajudar também."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma função personalizada para tratar a saida textual do LLM  \n",
    "  \n",
    "def separador_de_tweet(entrada: str) -> list:  \n",
    "    \"\"\"  \n",
    "    Função que recebe uma string e retorna uma lista com os elementos separados por quebras de linha.  \n",
    "    Args:        entrada (str): A string de entrada, onde os valores estão separados por quebras de linha.  \n",
    "    Returns:        list: Uma lista contendo cada elemento da string como um item separado.    \"\"\"    # Divide a string em uma lista utilizando o caractere de quebra de linha '\\n'  \n",
    "    elementos = entrada.split('\\n')  \n",
    "  \n",
    "    # Remove espaços extras e ignora linhas vazias  \n",
    "    elementos_limpos = [elemento.strip() for elemento in elementos if elemento.strip()]  \n",
    "  \n",
    "    return elementos_limpos  \n",
    "  \n",
    "# Criando uma função personalizada pegar a lista criada na função anterior e gerar um dicionário com o relátorio de  \n",
    "# analise de caracteres.  \n",
    "  \n",
    "def relatorio_de_analise_de_caracteres(entrada: list) -> dict:  \n",
    "    \"\"\"  \n",
    "    Função que gera um relatório com os tweets e a contagem de caracteres de cada tweet.  \n",
    "    Args:        entrada (list): Lista de strings representando os tweets.  \n",
    "    Returns:        dict: Um dicionário com duas chaves:              - 'tweets': contendo a lista original.              - 'num_caract': contendo uma lista com o número de caracteres de cada tweet.    \"\"\"    # Gera a contagem de caracteres para cada item na lista  \n",
    "    contagem_caracteres = [len(tweet) for tweet in entrada]  \n",
    "  \n",
    "    # Monta o dicionário de saída  \n",
    "    relatorio = {  \n",
    "        'tweets': entrada,  \n",
    "        'num_caract': contagem_caracteres  \n",
    "    }  \n",
    "  \n",
    "    return relatorio  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "  \n",
    "# Definindo o prompt de comunicação - adotamos aqui um estilo chat prompt  \n",
    "# template, uma vez que estamos usando o modelo do tipo chat.  \n",
    "  \n",
    "prompt_sistema = \"\"\"Você é um assistente especialista em criar conteúdo para o twitter e tem como objetivo  \n",
    "criar os melhores tweets virais sobre o tema que o usuário te passar. Seja criativo e atenda ao padrão de 280 caracteres do   \n",
    "twitter.  \n",
    "Orientação:  \n",
    "- Crie apenas o numero de tweets informado.  \n",
    "- Separe cada um deles por uma quebra de linha,  \n",
    "\"\"\"  \n",
    "  \n",
    "prompt_template = ChatPromptTemplate(  \n",
    "    [  \n",
    "        (\"system\", prompt_sistema),  \n",
    "        (\"human\", \"Crie um total de {numero_de_publicacoes} tweets sobre o tema {input_tema}.\"),  \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie a cadeia combinada usando LangChain Expression Language (LCEL).  \n",
    "# para adicionar os outros componentes personalizados à cadeia, precisamos converter as funções em um componente langchain, para isso  \n",
    "# precisamos usar o RunnableLambda.  \n",
    "  \n",
    "chain = prompt_template | llm | StrOutputParser() | RunnableLambda(separador_de_tweet) | RunnableLambda(relatorio_de_analise_de_caracteres)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executamos nossa chain  \n",
    "result = chain.invoke({\"numero_de_publicacoes\": 3, \"input_tema\": \"tecnologia\"})  \n",
    "  \n",
    "# Imprimimos o nosso dicionário de relatório:  \n",
    "print(result)  \n",
    "print(\"-\"*50)  \n",
    "  \n",
    "# imprimindo de forma mais estruturada:  \n",
    "for i, (tweet, num_caract) in enumerate(zip(result['tweets'], result['num_caract']), start=1):  \n",
    "        print(f\"Tweet {i}: {tweet}\")  \n",
    "        print(f\"Total de caracteres: {num_caract}\")  \n",
    "        if num_caract <= 280:  \n",
    "            print(\"Validação: OK\")  \n",
    "        else:  \n",
    "            print(\"Validação: Tweet supera o limite de 280 caracteres\")  \n",
    "        print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo - Chains de execução paralela\n",
    "\n",
    "Agora vamos a um problema mais complexo, imagine que queremos criar um assistente que recebe uma review de um filme e ele tem que analisar prós e contras comentados no review entregue na entrada.\n",
    "\n",
    "Para que possamos entender a execução paralela de chain, vamos criar uma arquitetura onde a análise pró e contra são realizadas de forma paralela, e no final vamos unir os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o prompt de comunicação - adotamos aqui um estilo chat prompt  \n",
    "# template, uma vez que estamos usando o modelo do tipo chat.  \n",
    "  \n",
    "prompt_template = ChatPromptTemplate.from_messages(  \n",
    "    [  \n",
    "        (\"system\", \"Você é um escritor especialista em análises de review de filmes de cinema.\"),  \n",
    "        (\"human\", \"Liste de forma estruturada os principais detalhes e pontos de vistas apresentados na seguinte  review entregue pelo usuário não invente nada apenas capture as principais informações apresentadas. Review: {movie_review}.\"),  \n",
    "    ]  \n",
    ")  \n",
    "\n",
    "  \n",
    "# Vamos definir um braço da nossa chain que será uma cadeia intermediária de analise dos pontos positivos sobre a review.  \n",
    "  \n",
    "analise_ponto_positivo_template = ChatPromptTemplate(  \n",
    "    [  \n",
    "        (\"system\", \"Você é um analista crítico de filmes de cinema\"),  \n",
    "        (  \n",
    "            \"human\", \"Dados este review estruturado: {review_estruturado}, liste os pontos positivos do filme.\",  \n",
    "        ),  \n",
    "    ]  \n",
    ")  \n",
    "\n",
    "# criando a chain do braço 1  \n",
    "chain_intermediaria_positiva = analise_ponto_positivo_template | llm | StrOutputParser()  \n",
    "  \n",
    "# -------------------------------------------------------------------------------- \n",
    "  \n",
    "# Vamos definir outro braço da nossa chain que será uma cadeia intermediária de analise dos pontos negativos sobre a review.  \n",
    "  \n",
    "analise_ponto_negativo_template = ChatPromptTemplate(  \n",
    "    [  \n",
    "        (\"system\", \"Você é um analista crítico de filmes de cinema\"),  \n",
    "        (  \n",
    "            \"human\", \"Dados este review estruturado: {review_estruturado}, liste os pontos negativos do filme.\",  \n",
    "        ),  \n",
    "    ]  \n",
    ")  \n",
    "  \n",
    "# criando a chain do braço 2  \n",
    "chain_intermediaria_negativa = analise_ponto_negativo_template | llm | StrOutputParser()  \n",
    "  \n",
    "# -------------------------------------------------------------------------------- \n",
    "  \n",
    "# Função responsável por combinar os resultados dos braços que vão ser executados em paralelo.  \n",
    "def combinando_analises(entrada: dict):  \n",
    "    return f\"Análise positiva:\\n{entrada['posivita']}\\n\\nAnálise negativa:\\n{entrada['negativa']}\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie a cadeia combinada usando LangChain Expression Language (LCEL)  \n",
    "# Em RunnableLambda(lambda x: {\"review_estruturado\": x}) estamos convertendo a saida string para um dicionário  \n",
    "# com a chave 'review_estruturado' que os templates das chains intermediárias exige como entrada.  \n",
    "  \n",
    "chain = (prompt_template  \n",
    "         | llm  \n",
    "         | StrOutputParser()  \n",
    "         | RunnableLambda(lambda x: {\"review_estruturado\": x})  \n",
    "         | {\"posivita\": chain_intermediaria_positiva, \"negativa\": chain_intermediaria_negativa}  \n",
    "         | RunnableLambda(combinando_analises)  \n",
    "         )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executando nossa chain principal.  \n",
    "movie_review =\"\"\"Crítica de \"O Gladiador 2\"  \n",
    "\"O Gladiador 2\", dirigido por Ridley Scott, chega aos cinemas com a expectativa de reviver a grandiosidade épica de   \n",
    "seu antecessor. No entanto, apesar do histórico impressionante de Scott, que inclui clássicos como \"Blade Runner\" e   \n",
    "\"Alien\", o filme parece tropeçar em sua própria ambição.  \n",
    "  \n",
    "Desde o início, o filme tenta inovar ao incorporar cenas animadas e elementos de inteligência artificial,   \n",
    "possivelmente como uma homenagem ao primeiro \"Gladiador\". No entanto, essa escolha estética, embora ousada,   \n",
    "não se integra de maneira fluida à narrativa, criando uma desconexão que pode confundir o espectador.  \n",
    "  \n",
    "A tentativa de trazer novidade às lutas no Coliseu, com a introdução de navios vikings e tubarões, é um exemplo   \n",
    "de como o filme busca surpreender. No entanto, essas cenas acabam por sacrificar a autenticidade histórica em prol   \n",
    "do espetáculo, o que pode afastar aqueles que esperavam uma representação mais fiel das arenas romanas. A inclusão   \n",
    "de macacos em combate, por sua vez, remete a outras franquias cinematográficas, diluindo ainda mais a originalidade   \n",
    "do enredo.  \n",
    "  \n",
    "Apesar dessas escolhas questionáveis, é importante reconhecer o esforço de Scott em tentar oferecer algo novo e   \n",
    "visualmente impactante. No entanto, a falta de uma pesquisa histórica mais aprofundada se faz sentir, e o filme   \n",
    "poderia ter se beneficiado de uma abordagem mais cuidadosa nesse aspecto.  \n",
    "  \n",
    "Em suma, \"O Gladiador 2\" é uma obra que, embora repleta de potencial e com momentos de brilho visual, acaba por se   \n",
    "perder em sua tentativa de inovar. Para os fãs do gênero e do diretor, pode ser uma experiência mista, que levanta   \n",
    "questões sobre até que ponto a inovação deve ir sem comprometer a essência e a coerência da narrativa.  \n",
    "\"\"\"  \n",
    "  \n",
    "result = chain.invoke({\"movie_review\": movie_review})  \n",
    "  \n",
    "# --------------------------------------------------------------------------------\n",
    "# Imprimindo a saida.  \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo - Chain de roteamento (Branch)\n",
    "\n",
    "Agora vamos a um problema onde teremos uma função de roteamento. Essa função terá a função de decidir, usando a classificação por meio de um LLM, para qual branch (braço/ramo) da nossa chain o programa deve seguir e finalizar.\n",
    "\n",
    "Imagine um sistema de atendimento com duas rotas: (1) quando o usuário solicita que seja atendido por um  humano, encaminhamos a pergunta para um atendente humano e finalizamos a cadeia ou (2) quando o usuário apenas deseja tirar dúvidas sobre um produto, nosso sistema escolhe enviar a pergunta para uma chain que implementa um bot capaz de responder às dúvidas desse usuário e finaliza a iteração.\n",
    "\n",
    "A peça principal desse nosso sistema está na criação de uma função que fará esse roteamento entre cadeias de LangChain. No nosso caso, você pode observar isso na função 'executa_roteamento' implementada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser  \n",
    "from pydantic import BaseModel, Field \n",
    "\n",
    "## Definindo a estrutura da chain que vai avaliar a entrada e retornar uma classificação para nossa função 'executa_roteamento'  \n",
    "# Definindo a minha estrutura de saída usando Pydantic  \n",
    "class Rota(BaseModel):  \n",
    "    opcao: bool = Field(description=\"Defina True se necessitar atendimento humano e false caso contrário.\")  \n",
    "    pergunta_user: str = Field(description=\"Colocar neste parametro a pergunta do usuário sem alterá-la.\")  \n",
    "  \n",
    "  \n",
    "parser = PydanticOutputParser(pydantic_object=Rota)  \n",
    "  \n",
    "sys_prompt_rota = \"\"\"Você é um especialista em classificação. Você receberá perguntas do usuário e precisará classificar, \n",
    "de forma booleana, se o usuário está solicitando conversar com um atendente humano ou não.  \n",
    "\\n{format_instructions}\\n  \n",
    "Pergunta Usuário: {pergunta_user}\"  \n",
    "\"\"\"  \n",
    "  \n",
    "rota_prompt_template = ChatPromptTemplate([(\"system\", sys_prompt_rota),],  \n",
    "                                          partial_variables={\"format_instructions\": parser.get_format_instructions()}  \n",
    "                                          )  \n",
    "  \n",
    "# criando o pedaço da chain que controla o roteamento entre as branches  \n",
    "chain_de_roteamento = rota_prompt_template | llm | parser  \n",
    "  \n",
    "# Se quiser testar a cadeia intermediária de roteamento:  \n",
    "# result = chain_de_roteamento.invoke({\"pergunta_user\": \"Quero falar com um humano\"})  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o prompt de chatbot que tira duvidas do usuário:  \n",
    "  \n",
    "sys_chatbot_prompt = \"\"\" Você é um assistente de uma clinica odontológica e tem como objetivo responder à perguntas dos clientes. A seguir você  \n",
    "encontra a FAQ do nosso site, use essas informações para realizar o atendimento e tirar dúvidas. Caso você desconheça alguma  \n",
    "informação, não invente. Seja sempre amigável e esteja disposto a ajudar!  \n",
    "  \n",
    "**FAQ - Clínica Odontológica**  \n",
    "1. **Quais serviços a clínica oferece?**    \n",
    "   Oferecemos tratamentos como limpeza dental, clareamento, ortodontia, implantes, próteses, tratamento de canal e estética dental.  \n",
    "2. **A clínica aceita convênios?**    \n",
    "   Sim, trabalhamos com os principais convênios odontológicos. Consulte nossa equipe para verificar se aceitamos o seu.  \n",
    "3. **Como agendar uma consulta?**    \n",
    "   Você pode agendar sua consulta pelo telefone, WhatsApp ou diretamente em nosso site.  \n",
    "4. **Quanto tempo dura uma consulta?**    \n",
    "   Depende do procedimento, mas consultas de rotina geralmente duram entre 30 e 60 minutos.  \n",
    "5. **Vocês atendem emergências?**    \n",
    "   Sim, oferecemos atendimento emergencial para dores agudas, traumas ou casos de urgência.  \n",
    "6. **É possível parcelar tratamentos?**    \n",
    "   Sim, oferecemos opções de parcelamento. Entre em contato para conhecer os detalhes.  \n",
    "7. **Crianças podem ser atendidas na clínica?**    \n",
    "   Sim, contamos com profissionais especializados em odontopediatria para cuidar dos sorrisos dos pequenos.  \n",
    "8. **O clareamento dental é seguro?**    \n",
    "   Sim, nossos tratamentos de clareamento são realizados com técnicas e produtos seguros, supervisionados por especialistas.  \n",
    "Se tiver mais dúvidas, entre em contato conosco! 😊  \n",
    "  \n",
    "Dúvida do usuário: {pergunta_user}  \n",
    "\"\"\"  \n",
    "  \n",
    "prompt_template_chatbot = ChatPromptTemplate.from_messages([(\"system\", sys_chatbot_prompt),])  \n",
    "  \n",
    "chain_chatbot = prompt_template_chatbot | llm | StrOutputParser()  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definindo a função de escolha de roteamento (nó de rota)  \n",
    "def executa_roteamento(entrada: Rota):  \n",
    "    if entrada.opcao:  \n",
    "        print(f\"Opção classe Pydantic: {entrada.opcao} (Atendimento humano)\")  \n",
    "        return \"Atendimento redirecionado para um humano. Favor aguardar alguns minutos que já vamos te atender!\"  \n",
    "    else:  \n",
    "        print(f\"Opção classe Pydantic: {entrada.opcao} (Atendimento Chatbot)\")  \n",
    "        return RunnableLambda(lambda x: {\"pergunta_user\": x.pergunta_user}) | chain_chatbot  \n",
    "\n",
    "\n",
    "# Crie a cadeia final usando LangChain Expression Language (LCEL)  \n",
    "chain = chain_de_roteamento | RunnableLambda(executa_roteamento) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executando nossa chain principal.  \n",
    "result = chain.invoke({\"pergunta_user\": \"Quais serviços a clínica oferece?\"})  \n",
    "  \n",
    "# -------------------------------------------------------------------------------- \n",
    "# Imprimindo a saida.  \n",
    "print(\"---------------\")  \n",
    "print(result)  \n",
    "print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Por que usar RouterChains?\n",
    "A principal vantagem de usar RouterChains é a capacidade de criar aplicações mais robustas e flexíveis. Imagine que você está desenvolvendo um chatbot para uma loja online. Com RouterChains, você pode direcionar perguntas sobre produtos eletrônicos para um especialista em eletrônicos, enquanto perguntas sobre roupas são direcionadas para um especialista em moda. Isso melhora a precisão e a relevância das respostas, proporcionando uma melhor experiência ao usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Classifique a pergunta do usuário em uma das seguintes categorias:\n",
    "        - Matemática\n",
    "        - Física\n",
    "        - Química\n",
    "        - Outras Informações\n",
    "\n",
    "        Pergunta: {query}\n",
    "        Classificação:\n",
    "        \"\"\"\n",
    "    )\n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")\n",
    "# Definindo os prompts especializados\n",
    "chain_fisica = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Você é um professor de física muito inteligente. Assuntos detalhados:\n",
    "        - Mecânica: Estuda o movimento e as causas que o produzem ou alteram. Inclui cinemática (estudo do movimento sem considerar suas causas), dinâmica (estudo das forças que causam o movimento) e estática (estudo do equilíbrio de corpos). \n",
    "        - Termologia: Estuda o calor, a temperatura e suas relações. Abrange tópicos como calorimetria (estudo da troca de calor), termodinâmica (estudo das leis que regem as transformações de energia térmica), e estados físicos da matéria. \n",
    "        - Ondulatória: Estuda as ondas, fenômenos como a propagação de energia através de um meio ou do espaço. \n",
    "        - Óptica: Estuda a luz e seus fenômenos, como reflexão, refração, difração e interferência. \n",
    "        - Eletromagnetismo: Estuda os fenômenos relacionados à eletricidade e ao magnetismo, incluindo eletrostática (estudo das cargas elétricas em repouso), eletrodinâmica (estudo das cargas em movimento), e magnetismo. \n",
    "        - Pessoas influentes da area\n",
    "        - Outras Informações\n",
    "\n",
    "        Pergunta: {query} \n",
    "        Resposta:\n",
    "        \"\"\"\n",
    "    )\n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")\n",
    "chain_matematica = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Você é um professor de matemática muito inteligente. Assuntos detalhados:\n",
    "        - Álgebra: Estuda as operações e relações entre números, incluindo equações, funções e polinômios.\n",
    "        - Geometria: Estuda as propriedades e relações de pontos, linhas, superfícies e sólidos no espaço.\n",
    "        - Trigonometria: Estuda as relações entre os ângulos e os lados dos triângulos.\n",
    "        - Cálculo: Estuda as taxas de variação e as somas infinitas, incluindo derivadas e integrais.\n",
    "        - Estatística: Estuda a coleta, análise e interpretação de dados numéricos.\n",
    "        - Pessoas influentes da area\n",
    "        - Outras Informações\n",
    "\n",
    "        Pergunta: {query} \n",
    "        Resposta:\n",
    "        \"\"\"\n",
    "    )\n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")\n",
    "chain_quimica = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Você é um professor de química muito inteligente. Assuntos detalhados:\n",
    "        - Estrutura Atômica: Estudo da composição do átomo, incluindo partículas subatômicas (prótons, nêutrons, elétrons), evolução dos modelos atômicos e distribuição eletrônica. \n",
    "        - Tabela Periódica: Organização dos elementos químicos, suas propriedades periódicas (eletroafinidade, energia de ionização, etc.) e relação com a estrutura atômica. \n",
    "        - Ligações Químicas: Tipos de ligações (iônica, covalente, metálica) e suas características, além de geometria molecular e polaridade. \n",
    "        - Funções Inorgânicas: Estudo de ácidos, bases, sais e óxidos, suas propriedades e reações. \n",
    "        - Reações Químicas: Tipos de reações, balanceamento de equações, reagente limitante, rendimento da reação e cálculo estequiométrico. \n",
    "        - Cálculos Químicos: Conceito de mol, número de Avogadro, massa molar, volume molar e cálculos relacionados a reações químicas. \n",
    "        - Termoquímica: Estudo do calor envolvido nas reações químicas, entalpia, lei de Hess e aplicações. \n",
    "        - Eletroquímica: Estudo da relação entre eletricidade e reações químicas, pilhas, eletrólise e potenciais de eletrodo. \n",
    "        - Química Orgânica: Estudo dos compostos de carbono, funções orgânicas, isomeria e reações orgânicas. \n",
    "        - Misturas e Separação de Misturas: Tipos de misturas (homogêneas e heterogêneas), métodos de separação (filtração, destilação, decantação, etc.). \n",
    "        - Equilíbrio Químico: Conceito de equilíbrio químico, constantes de equilíbrio, deslocamento do equilíbrio. \n",
    "        - Química Ambiental: Estudo da poluição ambiental, tratamento de resíduos e impacto das atividades humanas no meio ambiente. \n",
    "        - Radioatividade: Desintegração radioativa, tipos de radiação, meia-vida e aplicações da radioatividade.  \n",
    "        - Pessoas influentes da area\n",
    "        - Outras Informações\n",
    "\n",
    "        Pergunta: {query} \n",
    "        Resposta:\n",
    "        \"\"\"\n",
    "    )\n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")\n",
    "\n",
    "chain_prompt = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Responda à seguinte pergunta:\n",
    "\n",
    "        Pergunta: {query} \n",
    "        Resposta:\n",
    "        \"\"\"\n",
    "    )\n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um RunnableBranch é um tipo especial de executável que permite definir um conjunto de condições e executáveis a serem executados com base na entrada. Ele não oferece nada que você não possa obter em uma função personalizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "branch = RunnableBranch(\n",
    "    (lambda x: \"física\" in x[\"topic\"].lower(), chain_fisica),\n",
    "    (lambda x: \"química\" in x[\"topic\"].lower(), chain_quimica),\n",
    "    (lambda x: \"matemática\" in x[\"topic\"].lower(), chain_matematica),\n",
    "    chain_prompt,\n",
    ")\n",
    " \n",
    "\n",
    "full_chain = {\"topic\": chain, \"query\": lambda x: x[\"query\"]} | branch\n",
    "pretty_print(full_chain.invoke({\"query\": \"Quanto é 2 +2?\"}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    " \n",
    "\n",
    "# ela inicial (classificação)\n",
    "chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Classifique a pergunta do usuário em uma das seguintes categorias:\n",
    "        - Assuntos Financeiros\n",
    "        - Suporte Técnico\n",
    "        - Atualização de Cadastro\n",
    "        - Outras Informações\n",
    "\n",
    "        Pergunta: {query}\n",
    "        Classificação:\n",
    "        \"\"\"\n",
    "    )\n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")\n",
    "\n",
    "# elos específicos\n",
    "financial_chain = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Você é um especialista financeiro.\n",
    "    Sempre responda às perguntas começando com \"Bem-vindo ao Suporte Financeiro\".\n",
    "    Responda à pergunta do usuário:\n",
    "    Pergunta: {query}\n",
    "    Resposta:\n",
    "    \"\"\"\n",
    ") | llm\n",
    "tech_support_chain = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Você é um especialista em suporte técnico.\n",
    "    Sempre responda às perguntas começando com \"Bem-vindo ao Suporte Técnico\".\n",
    "    Ajude o usuário com seu problema técnico.\n",
    "    Pergunta: {query}\n",
    "    Resposta:\n",
    "    \"\"\"\n",
    ") | llm\n",
    "update_registration_chain = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Você é um representante de atendimento ao cliente.\n",
    "    Sempre responda às perguntas começando com \"Bem-vindo ao Suporte de Cadastro\".\n",
    "    Guie o usuário na atualização de suas informações de cadastro.\n",
    "    Pergunta: {query}\n",
    "    Resposta:\n",
    "    \"\"\"\n",
    ") | llm\n",
    "other_info_chain = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Você é um assistente de informações gerais.\n",
    "    Sempre responda às perguntas começando com \"Bem-vindo ao Suporte Geral\".\n",
    "    Forneça informações ao usuário sobre sua pergunta.\n",
    "    Pergunta: {query}\n",
    "    Resposta:\n",
    "    \"\"\"\n",
    ") | llm\n",
    " \n",
    " \n",
    "# Usando a RouterChain\n",
    "#resposta = router_chain.run(\"Qual é a segunda Lei de Newton?\")\n",
    "#print(resposta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de roteamento\n",
    "def route(info):\n",
    "    topic = info[\"topic\"].lower()\n",
    "    if \"financeiro\" in topic:\n",
    "        return financial_chain\n",
    "    elif \"técnico\" in topic:\n",
    "        return tech_support_chain\n",
    "    elif \"atualização\" in topic or \"cadastro\" in topic:\n",
    "        return update_registration_chain\n",
    "    else:\n",
    "        return other_info_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplos 1 suporte técnico\n",
    "classification = chain.invoke({\"query\": \"Como faço para redefinir minha senha?\"})\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chama a função rote, passando o topico\n",
    "response_chain = route({\"topic\": classification})\n",
    "print(response_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#executa o objeto correto\n",
    "response = response_chain.invoke({\"query\": \"Como faço para redefinir minha senha?\"})\n",
    "pretty_print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "router_chain = {\"topic\": chain, \"query\": lambda x: x[\"query\"]} | RunnableLambda(\n",
    "    route\n",
    ")\n",
    "\n",
    "query = \"Qual é a missão da empresa?\"\n",
    "#query = \"Como posso pagar uma fatura atrasada?\"\n",
    "#query = \"Preciso alterar meu endereço de e-mail.\"\n",
    "\n",
    "#query = \"Como faço para redefinir minha senha?\"\n",
    "\n",
    "resposta = router_chain.invoke({\"query\": query})\n",
    "pretty_print(resposta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "physics_template = \"\"\"Você é um professor de física muito inteligente.\n",
    "Você é ótimo em responder perguntas sobre física de forma concisa e fácil de entender.\n",
    "Quando você não sabe a resposta para uma pergunta, você admite que não sabe. \n",
    "\n",
    "Aqui vai uma pergunta, seja curto na resposta:\n",
    "{query}\"\"\"\n",
    "\n",
    "math_template = \"\"\"Você é um matemático muito bom. \n",
    "Você é ótimo em responder perguntas de matemática.\n",
    "Você é tão bom porque consegue decompor problemas difíceis em suas partes componentes, responder às partes componentes e, em seguida, juntá-las para responder à questão mais ampla.\n",
    "\n",
    "Aqui está uma pergunta, seja curto na resposta:\n",
    "{query}\"\"\"\n",
    "\n",
    "prompt_templates = [physics_template, math_template]\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
    " \n",
    "def prompt_router(input):\n",
    "    query_embedding = embeddings.embed_query(input[\"query\"])\n",
    "    \n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "    \n",
    "    most_similar = prompt_templates[similarity.argmax()]  \n",
    " \n",
    "    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\")\n",
    "    return PromptTemplate.from_template(most_similar)\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"query\": RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.invoke(\"What's a path integral?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchain)",
   "language": "python",
   "name": "grassato"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
